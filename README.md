# Obstacle-Avoidance-integrating-Safety-Bound-with-Reinforcement-Learning

This fork is used to provide an implementation for [1].

## Files

- main_RL_train_result.ipynb: main file for training and visualization.

- SafetyBound.py: obtain the size of safety bound.

- geometryCheck.py: check potential collision among different shapes.

- ObstacleAvoidanceENV.py: define RL environment, including transition model and reward function.

- plotting.py: visualization of RL training process

- draw.py: visualization of learned trajectories

- Q_learning.py: Q-learning algorithm




## Required python packages

- gym
- itertools
- matplotlib
- numpy
- pandas 
- sys
- matplotlib
- collections
- shapely
- math
- random
- sys

## Reference
[1] Hu, J., & Liu, Y. (2020). UAS conflict resolution integrating a risk-based operational safety bound as airspace reservation with reinforcement learning. In *AIAA Scitech 2020 Forum* (p. 1372).
